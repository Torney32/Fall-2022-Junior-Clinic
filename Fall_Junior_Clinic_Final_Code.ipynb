{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOyefb2l7gNu6+0winLH88S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Torney32/Fall-2022-Junior-Clinic/blob/main/Fall_Junior_Clinic_Final_Code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhGYL8hazFWG",
        "outputId": "8f609034-775e-4aed-a83b-0b2cc614723d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/MyDrive/Fall 2022 Semester/Machine Learning/Zillow-Data\n"
          ]
        }
      ],
      "source": [
        "#### importing libraries needed ####\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "import sklearn\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "from sklearn.preprocessing import LabelEncoder \n",
        "from zlib import crc32\n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, make_scorer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from datetime import date\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "%cd /content/gdrive/MyDrive/Fall\\ 2022\\ Semester/Machine\\ Learning/Zillow-Data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#### obtain the data ####\n",
        "train16 = pd.read_csv('Data/train_2016_v2.csv' , parse_dates=[\"transactiondate\"]) \n",
        "train17 = pd.read_csv('Data/train_2017.csv' , parse_dates=[\"transactiondate\"]) \n",
        "\n",
        "properties16 = pd.read_csv('Data/properties_2016.csv') \n",
        "properties17 = pd.read_csv('Data/properties_2017.csv') \n",
        "\n",
        "# Left join will ignore all properties that do not have a logerror (target variable) associated with them\n",
        "\n",
        "train16 = pd.merge(train16, properties16, how = 'left', on = 'parcelid')\n",
        "train17 = pd.merge(train17, properties17, how = 'left', on = 'parcelid')\n",
        "\n",
        "train = pd.concat([train16, train17], ignore_index=True)\n",
        "properties = pd.concat([properties16, properties17], ignore_index=True)\n",
        "\n",
        "sample = pd.read_csv('Data/sample_submission.csv') \n",
        "sample= sample.rename(columns={'ParcelId': 'parcelid'}) # To make it easier for merging datasets on same column_id later"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5JW7ZNGzSVn",
        "outputId": "292128a3-a703-41d6-eedd-d2a7a0364f9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py:3326: DtypeWarning: Columns (22,32,34,49,55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py:3326: DtypeWarning: Columns (49) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#### analyzing the data ####                     # (rows/homes, columns/data points)\n",
        "print(\"Training Size:\" + str(train.shape))       # Training Size:(167888, 60)\n",
        "print(\"Property Size:\" + str(properties.shape))  # Property Size:(2985217 * 2 = 5970434, 58)\n",
        "print(\"Sample Size:\" + str(sample.shape))        # Sample Size:(2985217, 7)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PA28b1uDzZn9",
        "outputId": "ded06e7e-f695-4408-aa3b-1c107046406c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Size:(167888, 60)\n",
            "Property Size:(5970434, 58)\n",
            "Sample Size:(2985217, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop rows with 75% or more NaN values\n",
        "drop_per = 75\n",
        "count_of_nan =  int(((100-drop_per)/100)*train.shape[1] + 1)\n",
        "train = train.dropna(axis=0, thresh=count_of_nan)\n",
        "train.shape #(167854, 60) So only 34 rows which meet this criteria"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mI3CIVl8zZyr",
        "outputId": "bbd6a937-de6c-4d67-94f8-fb5b718ad18f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(167854, 60)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating variable of all log-errors to be used later for evaluation\n",
        "y_all = train.logerror"
      ],
      "metadata": {
        "id": "HMhYenPmSdg9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Make sure there is no error in the dataset when splitting\n",
        "def error_checking(id, split):                                                         \n",
        "    return crc32(np.int64(id)) & 0xffffffff < split * 2**32     \n",
        "\n",
        "#Split the dataset by parcelid\n",
        "def data_split(train, split, parcelid):                                                  \n",
        "    identifier = train[parcelid]\n",
        "    for_testing = identifier.apply(lambda id_: error_checking(id_, split))\n",
        "    \n",
        "    x_train = train.loc[~for_testing]\n",
        "    x_test = train.loc[for_testing]\n",
        "\n",
        "    # Remove outliers from the training data\n",
        "    y = train.logerror\n",
        "    log_error_max = y.mean() + 2.5*y.std()\n",
        "    log_error_min = y.mean() - 2.5*y.std()\n",
        "\n",
        "    y_train = y[y > log_error_min]\n",
        "    y_train = y[y < log_error_max]\n",
        "\n",
        "    x_train = x_train[x_train.logerror > log_error_min]\n",
        "    x_train = x_train[x_train.logerror < log_error_max]\n",
        "    \n",
        "    # Create outputs ready to be used\n",
        "    x_train_op = x_train.drop(\"logerror\", axis=1)\n",
        "    y_train_op = x_train.logerror\n",
        "    x_test_op = x_test.drop(\"logerror\", axis=1)\n",
        "    y_test_op = x_test.logerror\n",
        "    return x_train_op, x_test_op, y_train_op, y_test_op\n",
        "\n",
        "x_train, x_test, y_train, y_test = data_split(train, 0.2, \"parcelid\")"
      ],
      "metadata": {
        "id": "VsMjIWEbzZ03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Training Dataset Shape: {x_train.shape}\")    # ~80% of instances are in training\n",
        "print(f\"Test Dataset Shape: {x_test.shape}\")         # 20% of instances are in test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RBRJRfWzZ3Q",
        "outputId": "09648a19-11e4-4a2c-9701-4a734a94ce58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Dataset Shape: (131617, 59)\n",
            "Test Dataset Shape: (33607, 59)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Class to call later to drop unwanted features\n",
        "class FeatureDropping(BaseEstimator, TransformerMixin):     \n",
        "    def __init__(self, labels):\n",
        "        self.labels = labels\n",
        "    def fit(self, input, y=None):\n",
        "        return self \n",
        "    def transform(self, input): \n",
        "        output = input.drop(self.labels, axis=1)\n",
        "        return output"
      ],
      "metadata": {
        "id": "5ydJ-Q9SzZ7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Class to create feature of the year and month\n",
        "class CreateMonthAndYearFeature(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        pass\n",
        "        \n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "    \n",
        "    def transform(self, input): \n",
        "        transdate = pd.to_datetime(input['transactiondate']).dt # Grab transactiondate feature\n",
        "        input['transaction_year_month'] = ((transdate.year - 2016)*12 + transdate.month).astype('category') # Create the year/month feature starting from Jan 2016\n",
        "        output = input.drop(['transactiondate'], axis=1) # Drop transactiondate as it is now replaced\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "id": "hjaQVBhfzaFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the mean average error of the input dataset\n",
        "def evaluate(algorithm, input, y_true):\n",
        "    for model in algorithm: \n",
        "        y_pred = model.predict(input)\n",
        "        mae = mean_absolute_error(y_true, y_pred)\n",
        "        print(f\"Algorithm: {model}\")\n",
        "        print(f\"MAE: {mae}\")"
      ],
      "metadata": {
        "id": "u_Mtxu4izaL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the statistics from cross validation\n",
        "def stats(algorithm, mae):\n",
        "    print(\"Algorithm:\", algorithm)\n",
        "    print(\"\\nMAE:\", mae)\n",
        "    print(\"\\nAverage:\", mae.mean())\n",
        "    print(\"\\nStandard deviation:\", mae.std())\n",
        "    \n",
        "# k-fold cross validation with MAE calculation\n",
        "def cross_validation(algorithm, input, y, cv=10, fit_params=None):\n",
        "    for model in algorithm: \n",
        "        mae = -cross_val_score(model, input, y, scoring=\"neg_mean_absolute_error\", cv=cv, fit_params=fit_params)\n",
        "        stats(model, mae)"
      ],
      "metadata": {
        "id": "B084wn0FzaN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create new variables to go through the pipeline\n",
        "pipe_train = x_train.copy()\n",
        "pipe_test = x_test.copy()\n",
        "all_parcels = train.drop(\"logerror\", axis=1)"
      ],
      "metadata": {
        "id": "xeLuR_8f3SEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Preparation\n",
        "# Drop these features which are duplicated or have over 75% of the data missing\n",
        "drop_features = [\"finishedsquarefeet13\", \"finishedsquarefeet15\", \"finishedfloor1squarefeet\", \"finishedsquarefeet50\",\n",
        "             \"storytypeid\", \"architecturalstyletypeid\", \"buildingclasstypeid\", \"typeconstructiontypeid\", \"finishedsquarefeet6\",\n",
        "             \"pooltypeid10\", \"pooltypeid7\", \"hashottuborspa\", \"fireplaceflag\", \"threequarterbathnbr\", \"calculatedbathnbr\",\n",
        "             \"fullbathcnt\", \"numberofstories\", \"rawcensustractandblock\", \"censustractandblock\",\n",
        "             \"finishedsquarefeet12\", \"taxvaluedollarcnt\", \"taxamount\", \"assessmentyear\", \"roomcnt\",\n",
        "             \"propertyzoningdesc\", \"regionidneighborhood\", \"regionidzip\", \"taxdelinquencyyear\",\n",
        "             \"propertycountylandusecode\", \"regionidcity\", \"parcelid\", \"basementsqft\", \"yardbuildingsqft26\"\n",
        "            ]\n",
        "\n",
        "feature_dropping = FeatureDropping(labels=drop_features)\n",
        "\n",
        "# Creating year and month feature\n",
        "year_month_create = CreateMonthAndYearFeature()\n",
        "\n",
        "# One hot encode the data\n",
        "encoding_features = ['transaction_year_month', \n",
        "            'airconditioningtypeid', 'buildingqualitytypeid', \n",
        "            'decktypeid', 'fips', 'heatingorsystemtypeid', 'pooltypeid2',\n",
        "            'propertylandusetypeid', 'regionidcounty',\n",
        "            'taxdelinquencyflag']\n",
        "            \n",
        "feature_encoder = ColumnTransformer([\n",
        "    (\"ohe_cats\", OneHotEncoder(handle_unknown='ignore'), encoding_features)\n",
        "],\n",
        "    remainder='passthrough'\n",
        ")"
      ],
      "metadata": {
        "id": "JoSAyxRs3SGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_processor = Pipeline([\n",
        "    ('feature_dropping', feature_dropping),\n",
        "    ('year_month_creator', year_month_create),\n",
        "    ('feature_encoder', feature_encoder),\n",
        "])\n",
        "\n",
        "data_pipeline = data_processor.fit(pipe_train)\n",
        "pipe_train = data_processor.transform(pipe_train)\n",
        "pipe_test = data_processor.transform(pipe_test)\n",
        "all_parcels = data_processor.transform(all_parcels)"
      ],
      "metadata": {
        "id": "Mkj_es1p3SKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize XGBoost and AdaBoost Models\n",
        "params = {\n",
        "    'learning_rate': 0.3,  #impacts how fast the model learns\n",
        "    'n_estimators': 10000, #times the model is optimized\n",
        "    'random_state': 42,    #keeps the same splits for every fold in cross validation to generate repeated data\n",
        "}\n",
        "\n",
        "xgb_base = xgb.XGBRegressor(**params)\n",
        "ada_base = AdaBoostRegressor(**params)"
      ],
      "metadata": {
        "id": "Tbv7VhiV3SQP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# XGBoost fit with validation using the test set\n",
        "fit_params={'early_stopping_rounds': 10, \n",
        "            'eval_metric': 'mae',\n",
        "            'eval_set': [[pipe_test, y_test]]}\n",
        "\n",
        "xgb_base.fit(pipe_train, y_train, **fit_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bl5G8GNx3SSa",
        "outputId": "162a0391-41c9-49fc-e4ff-16390ee4d6b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[07:49:39] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[0]\tvalidation_0-mae:0.352861\n",
            "Will train until validation_0-mae hasn't improved in 10 rounds.\n",
            "[1]\tvalidation_0-mae:0.254539\n",
            "[2]\tvalidation_0-mae:0.187748\n",
            "[3]\tvalidation_0-mae:0.142998\n",
            "[4]\tvalidation_0-mae:0.113697\n",
            "[5]\tvalidation_0-mae:0.095101\n",
            "[6]\tvalidation_0-mae:0.083761\n",
            "[7]\tvalidation_0-mae:0.077169\n",
            "[8]\tvalidation_0-mae:0.073505\n",
            "[9]\tvalidation_0-mae:0.0715\n",
            "[10]\tvalidation_0-mae:0.070416\n",
            "[11]\tvalidation_0-mae:0.069811\n",
            "[12]\tvalidation_0-mae:0.069494\n",
            "[13]\tvalidation_0-mae:0.069292\n",
            "[14]\tvalidation_0-mae:0.069173\n",
            "[15]\tvalidation_0-mae:0.069108\n",
            "[16]\tvalidation_0-mae:0.069061\n",
            "[17]\tvalidation_0-mae:0.069028\n",
            "[18]\tvalidation_0-mae:0.069007\n",
            "[19]\tvalidation_0-mae:0.068982\n",
            "[20]\tvalidation_0-mae:0.068978\n",
            "[21]\tvalidation_0-mae:0.068975\n",
            "[22]\tvalidation_0-mae:0.068971\n",
            "[23]\tvalidation_0-mae:0.068967\n",
            "[24]\tvalidation_0-mae:0.068958\n",
            "[25]\tvalidation_0-mae:0.068951\n",
            "[26]\tvalidation_0-mae:0.068926\n",
            "[27]\tvalidation_0-mae:0.068925\n",
            "[28]\tvalidation_0-mae:0.068921\n",
            "[29]\tvalidation_0-mae:0.068917\n",
            "[30]\tvalidation_0-mae:0.068913\n",
            "[31]\tvalidation_0-mae:0.068917\n",
            "[32]\tvalidation_0-mae:0.06891\n",
            "[33]\tvalidation_0-mae:0.068901\n",
            "[34]\tvalidation_0-mae:0.068897\n",
            "[35]\tvalidation_0-mae:0.068899\n",
            "[36]\tvalidation_0-mae:0.068897\n",
            "[37]\tvalidation_0-mae:0.068899\n",
            "[38]\tvalidation_0-mae:0.068899\n",
            "[39]\tvalidation_0-mae:0.068896\n",
            "[40]\tvalidation_0-mae:0.068895\n",
            "[41]\tvalidation_0-mae:0.068896\n",
            "[42]\tvalidation_0-mae:0.068903\n",
            "[43]\tvalidation_0-mae:0.068903\n",
            "[44]\tvalidation_0-mae:0.068897\n",
            "[45]\tvalidation_0-mae:0.068902\n",
            "[46]\tvalidation_0-mae:0.0689\n",
            "[47]\tvalidation_0-mae:0.068901\n",
            "[48]\tvalidation_0-mae:0.068898\n",
            "[49]\tvalidation_0-mae:0.068888\n",
            "[50]\tvalidation_0-mae:0.068887\n",
            "[51]\tvalidation_0-mae:0.068887\n",
            "[52]\tvalidation_0-mae:0.068883\n",
            "[53]\tvalidation_0-mae:0.068885\n",
            "[54]\tvalidation_0-mae:0.068887\n",
            "[55]\tvalidation_0-mae:0.06888\n",
            "[56]\tvalidation_0-mae:0.068877\n",
            "[57]\tvalidation_0-mae:0.068877\n",
            "[58]\tvalidation_0-mae:0.068872\n",
            "[59]\tvalidation_0-mae:0.068872\n",
            "[60]\tvalidation_0-mae:0.06888\n",
            "[61]\tvalidation_0-mae:0.068878\n",
            "[62]\tvalidation_0-mae:0.068885\n",
            "[63]\tvalidation_0-mae:0.068884\n",
            "[64]\tvalidation_0-mae:0.068881\n",
            "[65]\tvalidation_0-mae:0.068892\n",
            "[66]\tvalidation_0-mae:0.068888\n",
            "[67]\tvalidation_0-mae:0.068884\n",
            "[68]\tvalidation_0-mae:0.068884\n",
            "Stopping. Best iteration:\n",
            "[58]\tvalidation_0-mae:0.068872\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBRegressor(learning_rate=0.3, n_estimators=10000, random_state=42)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluating where ohe placed Nan columns\n",
        "\n",
        "len(np.where(np.isnan(pipe_train.data) == True)[0])\n",
        "np.where(np.isnan(pipe_train.sum(axis=0)) == True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1x4kYCA3SN5",
        "outputId": "f1f423ab-22ed-409b-a25c-4f4fae729f51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
              " array([81, 82, 83, 84, 87, 88, 89, 90, 91, 92, 93, 94]))"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating new variables for AdaBoost which are dense versions to remove Nan columns\n",
        "# from ohe\n",
        "\n",
        "x_train_ada = pipe_train.todense()[:, :80]\n",
        "x_test_ada = pipe_test.todense()[:, :80]\n",
        "x_all_ada = all_parcels.todense()[:, :80]"
      ],
      "metadata": {
        "id": "-qpliv2L9jyR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit AdaBoost\n",
        "\n",
        "ada_base.fit(x_train_ada, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUcfM7qB9uVL",
        "outputId": "9738a0fd-4b09-45f2-8d9a-8cdd2dd92463"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AdaBoostRegressor(learning_rate=0.3, n_estimators=10000, random_state=42)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# XGBoost cross val using all data\n",
        "\n",
        "fit_params={'early_stopping_rounds': 10, \n",
        "            'eval_metric': 'mae',\n",
        "            'verbose': False,\n",
        "            'eval_set': [[all_parcels, y_all]]}\n",
        "\n",
        "cross_validation([xgb_base], all_parcels, y_all, cv=10, fit_params=fit_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VXWAua9Rs0U",
        "outputId": "0f9339e5-fd1d-4564-c35c-6b47aa784af2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[07:50:07] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[07:50:17] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[07:51:24] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[07:51:37] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[07:52:07] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[07:52:34] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[07:52:49] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[07:53:03] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[07:53:16] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[07:53:27] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "Algorithm: XGBRegressor(learning_rate=0.3, n_estimators=10000, random_state=42)\n",
            "\n",
            "MAE: [0.0741531  0.07209707 0.06789544 0.06539838 0.06698872 0.07131061\n",
            " 0.07040414 0.06955762 0.06622741 0.07319263]\n",
            "\n",
            "Average: 0.06972251219275746\n",
            "\n",
            "Standard deviation: 0.002864436272882789\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# XGBoost cross val using dense data required by AdaBoost\n",
        "\n",
        "fit_params={'early_stopping_rounds': 10, \n",
        "            'eval_metric': 'mae',\n",
        "            'verbose': False,\n",
        "            'eval_set': [[x_all_ada, y_all]]}\n",
        "\n",
        "cross_validation([xgb_base], x_all_ada, y_all, cv=10, fit_params=fit_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upiX9YTZT534",
        "outputId": "a6490f92-31f9-45c8-90a6-59b27d4c62ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[08:02:25] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[08:02:38] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[08:02:49] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[08:03:06] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[08:03:18] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[08:03:33] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[08:03:46] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[08:03:55] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[08:04:03] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[08:04:20] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "Algorithm: XGBRegressor(learning_rate=0.3, n_estimators=10000, random_state=42)\n",
            "\n",
            "MAE: [0.0738554  0.07075051 0.06710109 0.06514223 0.06661816 0.07123644\n",
            " 0.07020288 0.06999901 0.06644837 0.07782619]\n",
            "\n",
            "Average: 0.06991802902481456\n",
            "\n",
            "Standard deviation: 0.0036637676855216027\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### AdaBoost Cross Val of the entire dataset\n",
        "\n",
        "cross_validation([ada_base], x_all_ada, y_all, cv=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VDAFN7xS5Af",
        "outputId": "fbb76dac-020e-416c-b089-6ca01b943743"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Algorithm: AdaBoostRegressor(learning_rate=0.3, n_estimators=10000, random_state=42)\n",
            "\n",
            "MAE: [0.08959906 0.07928853 0.08062522 0.08232769 0.08222798 0.13087609\n",
            " 0.12893187 0.07930143 0.08504402 0.07865351]\n",
            "\n",
            "Average: 0.09168753875524668\n",
            "\n",
            "Standard deviation: 0.019359448945422467\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# XGBoost assessment of the mae of the test set after training\n",
        "\n",
        "evaluate([xgb_base], pipe_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQlFhJi34OqF",
        "outputId": "ea790cf1-91af-46d3-afad-30628010463a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Algorithm: XGBRegressor(learning_rate=0.3, n_estimators=10000, random_state=42)\n",
            "MAE: 0.06887246418322239\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# AdaBoost assessment of the mae of the test set after training\n",
        "\n",
        "evaluate([ada_base], x_test_ada, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjXaVjXs4OtF",
        "outputId": "55b79c5e-4801-4771-fefe-d165c9c95512"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Algorithm: AdaBoostRegressor(learning_rate=0.3, n_estimators=10000, random_state=42)\n",
            "MAE: 0.07079247081225327\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# XGBoost assessment of the mae for the entire dataset\n",
        "\n",
        "evaluate([xgb_base], all_parcels, y_all)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9NWKIu2ZBuc",
        "outputId": "37878ae3-47a9-4c25-d2d6-265e149cfa30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Algorithm: XGBRegressor(learning_rate=0.3, n_estimators=10000, random_state=42)\n",
            "MAE: 0.06811895784601586\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# AdaBoost assessment of the mae for the entire dataset\n",
        "\n",
        "evaluate([ada_base], x_all_ada, y_all)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vX0QPnTYZKKf",
        "outputId": "6324c093-52da-4f67-b6db-ea7a456eb071"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Algorithm: AdaBoostRegressor(learning_rate=0.3, n_estimators=10000, random_state=42)\n",
            "MAE: 0.07019324500598069\n"
          ]
        }
      ]
    }
  ]
}